{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bd7b19c-b00e-4398-8c1c-f1a1035b56a7",
   "metadata": {},
   "source": [
    "# Overview of the Artifact Processing Code\n",
    "\n",
    "This code is designed to help you process multiple text artifacts using OpenAI’s API. It includes an example experiment that summarizes `.txt` files, handling errors and retries automatically. \n",
    "\n",
    "## What You Should Do\n",
    "\n",
    "1. **Study the Code**: Read through the code to understand how it works, focusing on:\n",
    "   - How files are added to a queue for processing.\n",
    "   - How the example function (`summarize_future_history`) applies the experiment.\n",
    "   - How errors and retries are handled.\n",
    "\n",
    "2. **Run the Code as Is**: Before modifying, ensure the code works in your environment:\n",
    "   - Place `.txt` files in the folder specified in the script (`data/future` by default).\n",
    "   - Run the script and confirm the output matches the description.\n",
    "\n",
    "3. **Modify for Your Experiments**:\n",
    "   - Replace the example function with one tailored to your experiment.\n",
    "   - Adapt the prompts, file types, or output format as needed.\n",
    "\n",
    "## Support Resources\n",
    "\n",
    "You are not alone! If you have questions or need help:\n",
    "- **ChatGPT**: Ask for assistance with adapting or debugging your code.\n",
    "- **Your Classmates**: Collaborate with teammates and even across teams to brainstorm and troubleshoot.\n",
    "- **Team 6**: Reach out to the coding support team for technical help.\n",
    "- **Your Instructor (Prof. Allen)**: I’m here to guide you and answer your questions.\n",
    "\n",
    "Take it step by step, and remember: experimenting is part of the process. You've got this!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709f665-13ce-4162-9077-f25820fd0dfa",
   "metadata": {},
   "source": [
    "## Reading and Validating Your OpenAI API Key\n",
    "\n",
    "This example script demonstrates how to securely read and validate your OpenAI API key from an external file. It is important to follow these instructions carefully to ensure that your key is correctly formatted and can be used with the OpenAI API.\n",
    "\n",
    "**Steps to Use This Code**:\n",
    "\n",
    "1. **Create a Text File for Your Key**:\n",
    "   - Create a `.txt` file named `Team 00 API Key.txt`. Replace `00` with your team number (e.g., `Team 01 API Key.txt`).\n",
    "   - If your file is stored in a subfolder (e.g., `keys/`), adjust the file path in the code accordingly.\n",
    "\n",
    "2. **File Format**:\n",
    "   - The first line of the file should be a comment or identifier (e.g., `team-00-key`).\n",
    "   - The second line must contain your actual API key, which should begin with `sk-svcacct-`.\n",
    "   - Example file content:\n",
    "     ```\n",
    "     team-00-key\n",
    "     sk-svcacct-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "     ```\n",
    "\n",
    "3. **How the Script Works**:\n",
    "   - The script checks if the file exists at the specified path.\n",
    "   - It reads the file and validates that:\n",
    "     - The file contains at least two lines.\n",
    "     - The key on the second line starts with the required prefix `sk-svcacct-`.\n",
    "\n",
    "4. **Example Usage**:\n",
    "   - Replace the file path in the script with your actual file path if different.\n",
    "   - Run the script in a Python environment. If successful, the first and last characters of the key will be printed for confirmation. Example output:\n",
    "     ```\n",
    "     Validated API key: sk-svc...XXXXX\n",
    "     ```\n",
    "\n",
    "5. **Handling Errors**:\n",
    "   - If the file is missing, incorrectly formatted, or the key is invalid, an error message will explain the issue:\n",
    "     - `FileNotFoundError`: The file does not exist at the specified path.\n",
    "     - `ValueError`: The file format is invalid, or the key does not start with `sk-svcacct-`.\n",
    "\n",
    "6. **Security Best Practices**:\n",
    "   - Never share your API key publicly or include it in source code that others can access.\n",
    "   - Use this script to validate and load the key securely.\n",
    "\n",
    "By following these instructions, you can ensure your OpenAI API key is properly loaded and ready for use in your final project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7ae91db-d910-439e-96c0-323d254baa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated API key: sk-svcacct-eJP7gnYRjprYl4S68AzSdD7z0p-d5PpUdJ7o-5IcA3nzJXCDpIdPGpSCp9nDdUKU8T3BlbkFJZT7kWHsinq3Nw0FVgd63Mv1EFzOc9SXafjI3dpUQxRwRx_SYr2B6xQvvf9cs4pX4gA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "api_key_file_path = \"Team 06 API Key.txt\"  # Replace 00 with the appropriate number\n",
    "# api_key_file_path = \"keys/Team 06 API Key.txt\"  # If your key is in a subfolder, you can include that like I did here\n",
    "\n",
    "def read_and_validate_api_key(file_path):\n",
    "    \"\"\"\n",
    "    Reads and validates the OpenAI API key from the given file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the file containing the API key.\n",
    "    \n",
    "    Returns:\n",
    "        str: The validated API key.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the file format is invalid or the key doesn't meet the specifications.\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"API key file '{file_path}' not found.\")\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Validate the file format\n",
    "    if len(lines) < 2:\n",
    "        raise ValueError(f\"API key file '{file_path}' must have at least two lines.\")\n",
    "    \n",
    "    # Strip the first line (e.g., \"team-00-key\") and validate the second line\n",
    "    raw_key = lines[1].strip()  # Second line is the key\n",
    "    if not raw_key.startswith(\"sk-svcacct-\"):\n",
    "        raise ValueError(f\"Invalid API key format in file '{file_path}'. Key must start with 'sk-proj-'.\")\n",
    "    \n",
    "    # Return the validated key\n",
    "    return raw_key\n",
    "\n",
    "# Example usage:\n",
    "try:\n",
    "    api_key = read_and_validate_api_key(api_key_file_path)\n",
    "    print(f\"Validated API key: {api_key}\") #{api_key[:8]}...{api_key[-6:]}\")  # Output only part of the key for confirmation\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c893de6-7034-4c6e-83fd-2a8e68384e8c",
   "metadata": {},
   "source": [
    "## Installing the OpenAI Package and Initializing the OpenAI Client\n",
    "\n",
    "This guide explains how to install the latest version of the OpenAI package, initialize the OpenAI client, and check the package version. It is essential to use the **latest version** of the package to ensure compatibility with your project.\n",
    "\n",
    "**Installing or Updating the OpenAI Package**:\n",
    "\n",
    "To ensure you have the correct version of the OpenAI package, follow these steps:\n",
    "\n",
    "- Install the OpenAI package if you don't have it:\n",
    "  ```python\n",
    "  pip install openai\n",
    "  ```\n",
    "\n",
    "- Update to the latest version if you already have an older version installed:\n",
    "  ```python\n",
    "  pip install --upgrade openai\n",
    "  ```\n",
    "\n",
    "**Code Explanation**:\n",
    "\n",
    "The Python code in the code cell below sets up your connection to the OpenAI API and verifies that your environment is using the latest package version.\n",
    "\n",
    "1. **Importing the OpenAI Object**:\n",
    "   - `from openai import OpenAI` imports the **OpenAI object**, which is required for interacting with OpenAI's API.\n",
    "\n",
    "2. **Creating the OpenAI Client**:\n",
    "   - `client = OpenAI(api_key=api_key)` creates the client that allows your program to communicate with OpenAI's API using your validated API key.\n",
    "\n",
    "3. **Printing the Package Version**:\n",
    "   - The `openai_version_module.__version__` attribute retrieves the current version of the OpenAI package installed in your environment.\n",
    "   - This is useful for ensuring that you are using the latest version. If not, run `pip install --upgrade openai` to update.\n",
    "\n",
    "By following these steps and using the latest version of the OpenAI package, you can correctly set up the client and ensure compatibility with the new API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e728af-65de-43e5-be9e-085b40210c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI package version: 1.59.9\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI object using the validated API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Print the OpenAI package version\n",
    "import openai as openai_version_module\n",
    "print(f\"OpenAI package version: {openai_version_module.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e83911-9f7e-4997-9cf2-34bedf7a3af1",
   "metadata": {},
   "source": [
    "## Test the API\n",
    "\n",
    "This code is provided as a test case. It uses the OpenAI client to generate a Python program that prints \"Hello, World.\" Here's a quick breakdown:\n",
    "\n",
    "1. **Function Purpose**:\n",
    "   - `generate_hello_world(client)` sends a request to the OpenAI API asking it to generate Python code that displays \"Hello, World.\"\n",
    "\n",
    "2. **How It Works**:\n",
    "   - The `client.chat.completions.create` method sends the prompt to the GPT-4o-mini model.\n",
    "   - The `messages` argument includes a system role (\"You are a helpful assistant.\") and a user query asking for the program.\n",
    "\n",
    "3. **Return Value**:\n",
    "   - The function extracts and returns the generated code from the API's response.\n",
    "\n",
    "4. **Output**:\n",
    "   - The generated code is printed to the console.\n",
    "\n",
    "If the API request fails, an error is raised with a descriptive message. If it succeeds, it should output something like this:\n",
    "\n",
    "```python\n",
    "print(\"Hello world\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e32d8949-65f0-4c09-9215-b01c9a85ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "print(\"Hello world\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def generate_hello_world(client):\n",
    "    \"\"\"\n",
    "    Generate a Python program that prints 'Hello, World' using OpenAI API.\n",
    "    \n",
    "    Args:\n",
    "        client: The initialized OpenAI API client.\n",
    "        \n",
    "    Returns:\n",
    "        str: The Python program generated by the API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send a query to the OpenAI API\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "                { \"role\": \"user\", \"content\": \"Write a program in Python that displays 'Hello world'. \"\n",
    "                 \"Only output the code. Do not output any commentary.\" },\n",
    "            ]\n",
    "        )\n",
    "        # Extract the generated program\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error connecting to OpenAI API: {e}\")\n",
    "\n",
    "content = generate_hello_world(client)\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b1bad-fef5-4c3d-ab73-1788f1d00f89",
   "metadata": {},
   "source": [
    "## Function to Send a Query to OpenAI's API\n",
    "\n",
    "This code defines a generic function, `generate_response`, to simplify sending queries to OpenAI's API. Here's a brief explanation:\n",
    "\n",
    "**Function Purpose**:\n",
    "- `generate_response(client, system_role, user_prompt, model=\"gpt-4o-mini\")` generates a response from the OpenAI API based on the specified system role and user prompt.\n",
    "\n",
    "**How It Works**:\n",
    "1. Arguments:\n",
    "   - `client`: The OpenAI API client used to send requests.\n",
    "   - `system_role`: A description of the AI's role or context. This helps set the \"personality\" or expertise of the AI. For example:\n",
    "     - You are a helpful assistant.\n",
    "     - You are an expert in 18th-century literature.\n",
    "   - `user_prompt`: The specific query or instruction you want the AI to address. For example:\n",
    "     - Write a poem about the moon.\n",
    "     - Explain the key events of the American Revolution in one paragraph.\n",
    "   - `model`: The AI model to use, with the default being \"gpt-4o-mini\". This parameter can remain as is unless otherwise instructed.\n",
    "\n",
    "2. API Request:\n",
    "   - Combines the `system_role` and `user_prompt` into a query and sends it to the OpenAI API.\n",
    "\n",
    "3. Response Handling:\n",
    "   - Extracts and returns the response content generated by the AI.\n",
    "\n",
    "**Example Usage**:\n",
    "The following example asks for a fact about Bratislava:\n",
    "- System Role: You are a knowledgeable assistant specializing in geography.\n",
    "- User Prompt: Tell me an interesting fact about Bratislava.\n",
    "\n",
    "The AI's response will include a fact aligned with the role and query provided.\n",
    "\n",
    "**Error Handling**:\n",
    "If there is an issue (e.g., network error or invalid API key), a descriptive error will be raised.\n",
    "\n",
    "This function is flexible and reusable for various queries, making it easier to interact with OpenAI's API.\n",
    "\n",
    "**Understanding Prompts**:\n",
    "\n",
    "1. System Prompt (System Role):\n",
    "   - Sets the tone, expertise, or behavior of the AI. For example:\n",
    "     - To make the AI polite and helpful: You are a helpful assistant.\n",
    "     - To make the AI an expert on a topic: You are an expert in quantum mechanics.\n",
    "   - This is like providing the AI with a \"job description.\"\n",
    "\n",
    "2. User Prompt:\n",
    "   - Specifies the exact question or task you want the AI to handle. For example:\n",
    "     - Explain how solar panels generate electricity.\n",
    "     - Summarize the book 'Pride and Prejudice' in one sentence.\n",
    "\n",
    "The system and user prompts work together to guide the AI's response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "103bff47-cfcd-4d76-a4fe-c91deaeb203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Tom Brady is widely regarded as one of the greatest quarterbacks in the history of the NFL, and his legacy is marked by numerous achievements, records, and contributions to the sport. Here are some key aspects of his legacy:\n",
      "\n",
      "### Championships and Records\n",
      "1. **Super Bowl Success**: Brady won seven Super Bowl titles (XXVI, XXXVI, XXXVIII, XLIX, LI, LIII with the New England Patriots, and LV with the Tampa Bay Buccaneers), more than any other player in NFL history.\n",
      "2. **Super Bowl MVPs**: He was named Super Bowl MVP five times, showcasing his ability to perform in critical moments.\n",
      "3. **Career Statistics**: Brady retired as the all-time leader in several key statistical categories, including passing touchdowns (624), passing yards (89,214), and career wins (251 as a starting quarterback).\n",
      "\n",
      "### Longevity and Performance\n",
      "1. **Longevity**: Brady’s career spanned 23 seasons, from 2000 to 2022, and he played at an elite level well into his 40s, which is unprecedented for a quarterback.\n",
      "2. **Consistency**: He maintained high performance across seasons, including multiple MVP awards throughout his career.\n",
      "\n",
      "### Influence on the Game\n",
      "1. **Game Management**: Known for his intelligence, work ethic, and preparation, Brady set a standard for quarterback play, particularly in how to manage games and make crucial decisions under pressure.\n",
      "2. **Offensive Innovations**: His ability to adapt to different offensive systems and work effectively with a variety of receivers has influenced how teams approach the quarterback position.\n",
      "\n",
      "### Cultural Impact\n",
      "1. **Marketability**: Brady became a cultural icon, transcending sports. He has appeared in commercials, documentaries, and has a significant presence on social media.\n",
      "2. **Inspiration and Role Model**: His dedication, competitive spirit, and discipline have inspired countless players and fans. He has emphasized the importance of mental preparation and physical fitness.\n",
      "\n",
      "### Off-field Contributions\n",
      "1. **Philanthropy**: Brady has been involved in various charitable endeavors, including his own nonprofit, the TB12 Foundation, which focuses on health and wellness.\n",
      "2. **Business Ventures**: Post-retirement, he has launched various business initiatives, including his TB12 sports performance brand and involvement in media, contributing to his legacy beyond football.\n",
      "\n",
      "### Overall Impact\n",
      "Brady's legacy is characterized not only by his individual records and accolades but also by his impact on the sport as a whole. He raised the bar for excellence at the quarterback position and is often referenced in debates about the greatest athletes across all sports. His work ethic, leadership, and success in high-pressure situations have left an indelible mark on the NFL and will influence future generations of players.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(client, system_role, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Generate a response using OpenAI API based on the provided system role and user prompt.\n",
    "    \n",
    "    Args:\n",
    "        client: The initialized OpenAI API client.\n",
    "        system_role (str): The system's role or context, e.g., \"You are a helpful assistant.\"\n",
    "        user_prompt (str): The user's query or instruction.\n",
    "        model (str): The name of the OpenAI model to use. Default is \"gpt-4o-mini\".\n",
    "        \n",
    "    Returns:\n",
    "        str: The response generated by the OpenAI API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Send the query to the OpenAI API\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                { \"role\": \"system\", \"content\": system_role },\n",
    "                { \"role\": \"user\", \"content\": user_prompt },\n",
    "            ]\n",
    "        )\n",
    "        # Extract and return the response content\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error connecting to OpenAI API: {e}\")\n",
    "\n",
    "# Example: Ask about Bratislava\n",
    "# You can replace the prompt here with anything you like!\n",
    "try:\n",
    "    system_role = \"You are a knowledgeable, helpful assistant specializing in sports information.\"\n",
    "    user_prompt = \"Tell me about the legacy of Tom Brady.\"\n",
    "    \n",
    "    response = generate_response(client, system_role, user_prompt)\n",
    "    print(\"Response:\")\n",
    "    print(response)\n",
    "except Exception as error:\n",
    "    print(f\"Error: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e45c5c-ae58-4888-affd-3b72ca0c8b35",
   "metadata": {},
   "source": [
    "### Multiline Strings and String Concatenation in Python\n",
    "\n",
    "**Multiline Strings**:\n",
    "In Python, you can create strings that span multiple lines using triple quotes (`\"\"\"` or `'''`):\n",
    "\n",
    "```python\n",
    "\"\"\"This is a string\n",
    "that spans multiple lines.\n",
    "It is useful for long messages or formatted text.\"\"\"\n",
    "```\n",
    "\n",
    "**String Concatenation**:\n",
    "Strings can be combined (concatenated) using the `+` operator:\n",
    "\n",
    "```python\n",
    "part1 = \"Hello\"\n",
    "part2 = \"World\"\n",
    "combined = part1 + \" \" + part2  # Result: \"Hello World\"\n",
    "```\n",
    "\n",
    "**Best Practice for Long User Prompts**:\n",
    "Use concatenation to dynamically build strings:\n",
    "\n",
    "```python\n",
    "user_shape = 'circle'\n",
    "user_prompt = \"Write a Python program \" + \\\n",
    "              \"that calculates the area of a \" + user_shape + \".\"\n",
    "```\n",
    "\n",
    "**When to Use Each**:\n",
    "\n",
    "- **Multiline strings** are best for **long, fixed messages.**\n",
    "- **Concatenation** is helpful when parts of the string are **generated dynamically or come from variables.**\n",
    "\n",
    "By understanding these concepts, you can effectively create and customize prompts for the AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d38617-dd6a-452a-9660-48ec64cb19ba",
   "metadata": {},
   "source": [
    "## Summarizing a Future History with OpenAI\n",
    "\n",
    "This example demonstrates how to use the OpenAI API to analyze and summarize a student artifact called a \"future history.\" The provided function reads the text of the file, sends it to OpenAI's API with a specific prompt, and returns a one-sentence summary. You can copy and modify this function for your own experiments with OpenAI.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **The Function**:\n",
    "   - `summarize_future_history` is designed to:\n",
    "     - Read the content of a text file.\n",
    "     - Use OpenAI's API to generate a one-sentence summary of a future history.\n",
    "\n",
    "2. **The Prompts**:\n",
    "   - **System Prompt**: Explains to the AI what a \"future history\" is and sets the task's context.\n",
    "   - **User Prompt**: Provides the file's text and asks the AI to summarize it in one sentence.\n",
    "\n",
    "3. **The Test Code**:\n",
    "   - Reads the file `data/future/future_history_0909.txt`.\n",
    "   - Passes the file content to the function.\n",
    "   - Outputs the generated summary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8dfcc-6253-487d-a076-a6070499ad56",
   "metadata": {},
   "source": [
    "**Simple understanding of the next block of code**:\n",
    "\n",
    "If you would like for ChatGPT to take into account the instructions and rubric of this assignment, then this is what you have to do.\n",
    "On Moodle, under Final Project, there is a link called \"Documents provided by client (updated 1/23 Thu)\" that will take you to OneDrive.\n",
    "There, you need to download \"instructions-history.txt\" and \"rubric-history-1.txt\"\n",
    "Then, go to the \"code-and-data-quick-start\" folder that you've been using for this assignment, and create a new folder titled \"Information\"\n",
    "In that folder, you will add \"instructions-history.txt\" and \"rubric-history-1.txt\"\n",
    "Then, this code should run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85e4bcd5-68d6-4a23-983b-0f6aa51c84b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "I understand the provided content. The assignment is for students to write a \"Future History\" narrative, imagining their first year of college has already taken place and writing a letter to a high school friend about that experience. The purpose of the exercise is to help students vividly envision their future by narrating it in the past tense, encouraging introspection and creativity. \n",
      "\n",
      "The rubric categorizes the assessment criteria into six areas, evaluating aspects such as the use of perspective, vividness and specificity of details, reflection on growth, organizational coherence, use of freewriting and revision, and overall writing quality. Each category is graded on a scale from Beginning to Exemplary, guiding students on how to enhance their writing to meet expectations. \n",
      "\n",
      "If you have any more specific questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "def generate_understanding(client, system_role, instructions_content, rubric_content, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"\n",
    "    Generate a response using OpenAI API to confirm understanding of two provided files.\n",
    "    \n",
    "    Args:\n",
    "        client: The initialized OpenAI API client.\n",
    "        system_role (str): The system's role or context, e.g., \"You are a helpful assistant.\"\n",
    "        instructions_content (str): The content of the instructions file.\n",
    "        rubric_content (str): The content of the rubric file.\n",
    "        model (str): The name of the OpenAI model to use. Default is \"gpt-4o-mini\".\n",
    "        \n",
    "    Returns:\n",
    "        str: The response generated by the OpenAI API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the prompt\n",
    "        user_prompt = f\"\"\"\n",
    "        I am providing you with two files to understand the context of the assignment. Give a brief understanding of what the assignment is. Here are the files:\n",
    "        1. Instructions on what to accomplish in the future history:\n",
    "        {instructions_content}\n",
    "\n",
    "        2. Rubric on how the assignment is judged or graded:\n",
    "        {rubric_content}\n",
    "\n",
    "        Please confirm that you now understand the provided content.\n",
    "        \"\"\"\n",
    "\n",
    "        # Send the query to the OpenAI API\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                { \"role\": \"system\", \"content\": system_role },\n",
    "                { \"role\": \"user\", \"content\": user_prompt },\n",
    "            ]\n",
    "        )\n",
    "        # Extract and return the response content\n",
    "        return completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error connecting to OpenAI API: {e}\")\n",
    "\n",
    "# Example: Providing files for understanding\n",
    "try:\n",
    "    # System role\n",
    "    system_role = \"You are a helpful assistant that reads the files given to it and understands what is trying to be accomplished. This will be helpful when reviewing the future histories.\"\n",
    "\n",
    "    # Read the content of the files\n",
    "    instructions_history_path = \"information/instructions-history.txt\"\n",
    "    rubrics_history_path = \"information/rubric-history-1.txt\"\n",
    "\n",
    "    with open(instructions_history_path, 'r') as file:\n",
    "        instructions_content = file.read()\n",
    "\n",
    "    with open(rubrics_history_path, 'r') as file:\n",
    "        rubric_content = file.read()\n",
    "\n",
    "    # Generate the response\n",
    "    response = generate_understanding(client, system_role, instructions_content, rubric_content, model=\"gpt-4o-mini\")\n",
    "    print(\"Response:\")\n",
    "    print(response)\n",
    "except Exception as error:\n",
    "    print(f\"Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fdf3458-e4b5-4db1-948d-f2407c1dc753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the future history for data/future/future_history_nojo.txt:\n",
      "The narrative reflects on a transformative college experience at Centre College, highlighting academic achievements, athletic endeavors, meaningful relationships, and future plans for a gap year and graduate studies.\n"
     ]
    }
   ],
   "source": [
    "# Simplified function to summarize a future history\n",
    "def summarize_future_history(client, file_path):\n",
    "    \"\"\"\n",
    "    Summarize the content of a future history file using OpenAI API.\n",
    "    \n",
    "    Args:\n",
    "        client: The initialized OpenAI API client.\n",
    "        file_path (str): Path to the file to be summarized.\n",
    "    \n",
    "    Returns:\n",
    "        str: The one-sentence summary of the future history.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the file content\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            file_content = f.read()\n",
    "\n",
    "        # System prompt\n",
    "        system_role = (\n",
    "            \"You are a helpful assistant. Your task is to read future histories written by students.\"\n",
    "            \" A 'future history' is a narrative written in past tense about events that the writer imagines will happen in the future.\"\n",
    "        )\n",
    "\n",
    "        # User prompt with the file content\n",
    "        user_prompt = f\"Summarize the future history in one sentence.:\\n\\n{file_content}\"\n",
    "\n",
    "        # Call the existing generate_response function\n",
    "        response = generate_response(client, system_role, user_prompt, 'gpt-4o')\n",
    "\n",
    "        return response.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error summarizing file '{file_path}': {e}\")\n",
    "\n",
    "# Test code\n",
    "try:\n",
    "    file_path = \"data/future/future_history_nojo.txt\"  # Update with the correct file path\n",
    "    summary = summarize_future_history(client, file_path)\n",
    "    print(f\"Summary of the future history for {file_path}:\")\n",
    "    print(summary)\n",
    "except Exception as error:\n",
    "    print(f\"Error: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44ca2f-e082-441a-afa0-5534c76e07a1",
   "metadata": {},
   "source": [
    "### Modifying the Code Above\n",
    "\n",
    "You can adapt the code above for your own projects by following these steps:\n",
    "\n",
    "1. **Change the File Path**:\n",
    "   - Replace `data/future/future_history_0909.txt` with the path to your own text file.\n",
    "\n",
    "2. **Update the Prompts**:\n",
    "   - Modify the system prompt to give the AI a new context or purpose. For example:\n",
    "     - \"You are an assistant helping students improve their creative writing.\"\n",
    "   - Update the user prompt to ask for something different. For example:\n",
    "     - \"Rewrite the following text to make it more descriptive.\"\n",
    "\n",
    "3. **Experiment with the Output**:\n",
    "   - Try asking the AI for more detailed responses by changing the prompt to:\n",
    "     - \"Summarize the following future history in 3-5 sentences.\"\n",
    "   - You can also switch the model from `gpt-4o` to another model if directed.\n",
    "\n",
    "4. **Reuse for Different Tasks**:\n",
    "   - Use the same structure to ask the AI to:\n",
    "     - Provide feedback on writing.\n",
    "     - Generate new content based on the provided text.\n",
    "     - Analyze text for themes or patterns.\n",
    "\n",
    "### Notes for Experiments\n",
    "\n",
    "- Ensure the text you provide is appropriate for the task.\n",
    "- You can experiment with prompt phrasing to refine the AI's responses.\n",
    "- If the output isn’t what you expect, adjust the prompts or try breaking long files into smaller sections.\n",
    "\n",
    "By modifying this example, you can explore a variety of tasks with OpenAI's API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fac630-aa21-4e92-8ae1-33d0ebf1a25b",
   "metadata": {},
   "source": [
    "## Summarizing `.txt` Files with OpenAI: How This Code Works\n",
    "\n",
    "This script processes all `.txt` files in a specified folder (`data/future/` by default) and sends them to OpenAI’s API for analysis. It applies the `summarize_future_history` function, which generates a one-sentence summary for each artifact. Here’s how it works:\n",
    "\n",
    "1. The script scans the folder for files with the `.txt` extension and adds them to a queue for processing.\n",
    "2. Each file is processed by the `summarize_future_history` function, which reads the file content, sends it to OpenAI, and retrieves a summary.\n",
    "3. If the API fails to process a file, the script retries up to three times with increasing delays (1, 2, and 4 seconds).\n",
    "4. For each file, the script outputs the file name and its generated summary. Files that fail after all retries are skipped.\n",
    "\n",
    "This setup ensures reliable processing of all `.txt` files in the folder, handling errors and skipping non-text files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13449193-927e-4939-99c7-c268270f5cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing file: data/future/future_history_4909.txt\n",
      "Summary:\n",
      "In Spring 2025, I grew personally and academically by stepping outside my comfort zone through challenging classes, overcoming routine struggles after my athletic season, becoming more involved in campus organizations, and achieving various goals while also nurturing my faith and relationships.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_7187.txt\n",
      "Summary:\n",
      "The writer describes their successful and enjoyable first year of college, highlighting involvement in a rock climbing club, maintaining good grades with the support of academically minded friends, and overcoming initial challenges in adjusting to college life.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_3123.txt\n",
      "Summary:\n",
      "The writer reflects on their fulfilling college experience, highlighting strong friendships, participation in volleyball and cultural events, excellent dining and activity options, impressive academic opportunities, and supportive faculty that helped with their dental school application.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_6128.txt\n",
      "Summary:\n",
      "The student had a successful and enjoyable spring semester, achieving a 3.5 GPA, excelling in computer science, participating in sports and diving, and enjoying a spring break trip to Pensacola, Florida.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_5805.txt\n",
      "Summary:\n",
      "This spring was incredibly successful and fulfilling, with the writer achieving straight A's, securing a spot in the Strasbourg Abroad trip with friends, winning a defensive player award, reaching the Elite 8, and enjoying the happiness and safety of loved ones.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_2063.txt\n",
      "Summary:\n",
      "The future history describes the author's fulfilling final semester at Centre College, marked by academic achievements, a successful lacrosse season, and meaningful relationships, culminating in graduation and preparation to start a career at Deloitte.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_5134.txt\n",
      "Summary:\n",
      "In 2025, a student reflects on their fulfilling and memorable last semester of college, enriched by meaningful friendships, a rewarding internship, and valuable experiences that clarified their career path in education.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_1622.txt\n",
      "Summary:\n",
      "The author reflects on a successful and memorable final semester at college, balancing academics and personal life, cherishing friendships, and planning to work before attending graduate school.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_3155.txt\n",
      "Summary:\n",
      "Despite a challenging semester with a heavier workload, the writer successfully prioritized their major classes, made time for research, and enjoyed volunteering and social activities, while looking forward to the summer.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_6773.txt\n",
      "Summary:\n",
      "The student reflects on their successful and transformative first year of college, highlighting personal growth, meaningful friendships, academic challenges, and a sense of belonging within the campus community.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_7519.txt\n",
      "Summary:\n",
      "Reflecting on their challenging yet rewarding journey, a graduating senior shares experiences of switching majors, achieving success with the baseball team, completing a meaningful internship, and embracing valuable life lessons throughout their college years.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_3582.txt\n",
      "Summary:\n",
      "Reflecting on my first year of college, I successfully achieved my fitness and academic goals, saved money, overcame personal challenges, and began developing a promising business, all contributing to a fulfilling and purposeful life.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_0909.txt\n",
      "Summary:\n",
      "The student had an exciting and fulfilling semester, highlighted by sorority rush, successful conference championships, engaging classes, and enjoyable campus events.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_5913.txt\n",
      "Summary:\n",
      "Over the course of their first year at Centre, the student achieved a 4.0 GPA, formed meaningful relationships, got accepted into a study abroad program, discovered a potential career path, prioritized their health, and overcame personal and academic challenges, emerging more independent and resilient.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_5286.txt\n",
      "Summary:\n",
      "Over the past year, the writer has successfully balanced academics, extracurricular activities, and travel while navigating personal challenges and growth, culminating in presenting a research paper at a conference and forming deeper connections with new people.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_0287.txt\n",
      "Summary:\n",
      "The writer's final spring semester at Centre was filled with reflection and appreciation for growth, as they prepared to transition into the working world with plans to start a job in Louisville and explore career paths.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_6782.txt\n",
      "Summary:\n",
      "A student's final semester of college was a fulfilling and successful experience, balancing challenging and enjoyable classes, athletic achievements, personal growth, and exciting travel plans to Germany.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_2719.txt\n",
      "Summary:\n",
      "The writer reflects on a transformative first year of college filled with new friendships, hobbies, and personal growth, while expressing optimism and modest expectations for continued success and memorable experiences in the coming year.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_3401.txt\n",
      "Summary:\n",
      "The narrator reflects on their transformative experiences at Centre College, highlighting academic achievements, sports participation, and meaningful relationships, as they prepare for a gap year working in Chicago and a subsequent Master's degree.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_2829.txt\n",
      "Summary:\n",
      "In a challenging yet fulfilling spring semester, the writer successfully balanced three campus jobs, extracurricular leadership roles, and a politics-focused course load, ultimately achieving academic excellence and personal growth by mastering work-life balance and time management.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_9217.txt\n",
      "Summary:\n",
      "Reflecting on his transformative college experience, a man recalls the pivotal morale-boosting trip to Scotland with his football team, leading to two national championships, lifelong friendships, and shaping his professional and personal identity.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_2237.txt\n",
      "Summary:\n",
      "The student reflects on their growth during senior year, transitioning from uncertainty and struggle to personal and academic development, with gratitude for the journey and trust in the future.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_2619.txt\n",
      "Summary:\n",
      "Henry reflects on his transformative first year at Centre College, highlighting his academic growth, cultural experiences, and the friendships formed, while expressing eagerness for further exploration and development in the coming year.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_2744.txt\n",
      "Summary:\n",
      "A successful year of studies and extracurricular involvement led to strong friendships, joining a fraternity, and considerations for a future business double major, with goals to further explore career options and connections.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_nojo.txt\n",
      "Summary:\n",
      "A recent Centre College graduate reflects on their transformative college journey, including academic achievements, athletic experiences, and meaningful connections, while planning a gap year in Chicago and future graduate studies.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarizing file: data/future/future_history_7002.txt\n",
      "Summary:\n",
      "In the future, I hope to have developed a well-rounded resume reflecting academic excellence and personal growth, while contributing positively to my sports team's success.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from queue import Queue\n",
    "\n",
    "# If necessary, replace `data/future` with the path to where your artifacts are located\n",
    "artifacts_file_path = 'data/future/'\n",
    "\n",
    "# Create a queue for files to be processed\n",
    "file_queue = Queue()\n",
    "\n",
    "# Add files to the queue\n",
    "# Use os.listdir to list all files in the directory\n",
    "for file_name in os.listdir(artifacts_file_path):\n",
    "    file_path = os.path.join(artifacts_file_path, file_name)\n",
    "    if os.path.isfile(file_path) and file_name.lower().endswith(\".txt\"):\n",
    "        file_queue.put(file_path)\n",
    "\n",
    "# Parameters for retrying failed files\n",
    "max_retries = 3  # Maximum number of retries for a single file\n",
    "retry_delays = [1, 2, 4]  # Delays between retries in seconds (exponential backoff)\n",
    "\n",
    "# Track attempts for each file\n",
    "attempts = {}\n",
    "\n",
    "while not file_queue.empty():\n",
    "    file_path = file_queue.get()\n",
    "    attempts[file_path] = attempts.get(file_path, 0) + 1\n",
    "\n",
    "    try:\n",
    "        # Call the summarization function\n",
    "        summary = summarize_future_history(client, file_path)\n",
    "\n",
    "        # Output the result\n",
    "        print(f\"Summarizing file: {file_path}\")\n",
    "        print(\"Summary:\")\n",
    "        print(summary)\n",
    "        print(\"\\n\" + \"-\" * 50 + \"\\n\")  # Separator for readability\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error processing file '{file_path}': {error}\")\n",
    "\n",
    "        # Retry if the file hasn't reached the max retries\n",
    "        if attempts[file_path] <= max_retries:\n",
    "            print(f\"Retrying file: {file_path} (attempt {attempts[file_path]})\")\n",
    "            file_queue.put(file_path)  # Add back to the queue\n",
    "\n",
    "            # Add delay for retries\n",
    "            time.sleep(retry_delays[min(attempts[file_path] - 1, len(retry_delays) - 1)])\n",
    "        else:\n",
    "            print(f\"Max retries reached for file: {file_path}. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efec180-e664-4d28-986a-86b61f572f02",
   "metadata": {},
   "source": [
    "## How to Adapt This Script for Your Experiments\n",
    "\n",
    "You can modify this script to apply different experiments to your artifacts. To keep your work organized, consider creating a new Jupyter notebook for each experiment. Here’s how to adapt it:\n",
    "\n",
    "1. Replace the `summarize_future_history` function with one that performs your experiment. For example:\n",
    "   - Analyzing text for themes.\n",
    "   - Providing feedback on writing.\n",
    "   - Rewriting text for a different purpose.\n",
    "\n",
    "   Example:\n",
    "\n",
    "   ```python\n",
    "   def analyze_themes(client, file_path):\n",
    "       # Custom function for analyzing themes\n",
    "       return result\n",
    "   ```\n",
    "\n",
    "3. Change the file path to point to your folder of artifacts:\n",
    "\n",
    "   ```python\n",
    "   all_files_path = \"path/to/your/files/\"\n",
    "   ```\n",
    "\n",
    "5. Adjust the file type filter if you want to process files other than `.txt`:\n",
    "   ```python\n",
    "   if os.path.isfile(file_path) and file_name.lower().endswith(\".md\"):\n",
    "   ```\n",
    "\n",
    "7. Modify the output to suit your experiment. For example, save results to a file:\n",
    "\n",
    "   ```python\n",
    "   with open(\"experiment_results.txt\", \"a\", encoding=\"utf-8\") as output_file:\n",
    "       output_file.write(f\"File: {file_path}\\nResult:\\n{result}\\n\\n\")\n",
    "   ```\n",
    "   \n",
    "9. Create separate Jupyter notebooks for each experiment. Include:\n",
    "   - Your custom function.\n",
    "   - This script, modified to call your function.\n",
    "\n",
    "By keeping each experiment in its own notebook, you’ll have a clear record of your work and can easily manage different analyses with OpenAI’s API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efabeb3-edac-4c09-9d82-b2447bd2e904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
